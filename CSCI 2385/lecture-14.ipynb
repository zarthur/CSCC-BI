{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survey of Unsupervised Learning Methods\n",
    "\n",
    "In this survey of learning methods, we'll look at implementations of the following algorithms.\n",
    "\n",
    "- K-Means\n",
    "- DBSCAN\n",
    "- Principle Component Analysis\n",
    "\n",
    "## Preparing the Environment\n",
    "\n",
    "To perform these machine learning tasks, we'll make use of the following libraries and their dependencies.\n",
    "\n",
    "- sklearn - a machine learning library\n",
    "- seaborn - a data visualization library\n",
    "- pandas - library providing the data structures in which we'll store our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sklearn seaborn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also configure plotting.  First we ensure that generated plots appear in the notebook itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set the figure size for plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12,8)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab\n",
    "\n",
    "For this lab, we'll work with the [Iris Flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set) again. Though there are existing categories, we'll try to determine clusters using the K-means and DBSCAN alogorithms.\n",
    "\n",
    "### Loading the Data\n",
    "\n",
    "We start by loading the data.  This data set is among the example datasets included with Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = sns.load_dataset('iris')\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that there are 150 rows of data; each of the three species has a 50 sets of measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(iris_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data\n",
    "\n",
    "Before applying the clustering algorithms, it's helpful to explore the data in order to get an understanding of the input values.  An understanding of the data will help to evaluate the models produced by the algorithms and determine how well they perform.\n",
    "\n",
    "Looking at the pair-wise scatter plots, we see that there at least two distinct clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of petal/sepal length and width, our data is four-dimensional. Looking at two-dimensional \"slices\" doesn't show us if obvious groups of points exist in higher dimensions.  While we cannot easily visualize four-dimensional data, we can visualize three-dimensional data.  We can create scatter plots of three of the four dimensions.  Tjhere are four ways of choosing any three dimensions from the four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "input_data = iris_data.drop('species', axis=1)\n",
    "three_dimensions = list(itertools.combinations(input_data.columns, 3))\n",
    "three_dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates four three-dimensional scatter plots.  Note that we use the `%matplotlib notebook` command to make these interactive. You might have to run the cell twice to see the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "for column_names in three_dimensions:\n",
    "    x_dim, y_dim, z_dim = column_names\n",
    "    \n",
    "    # extract data from DataFrame\n",
    "    x_data = input_data[x_dim]\n",
    "    y_data = input_data[y_dim]\n",
    "    z_data = input_data[z_dim]\n",
    "\n",
    "    # create figure with 3d projection\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # plot the data\n",
    "    ax.scatter(x_data, y_data, z_data)\n",
    "    \n",
    "    # set axes labels\n",
    "    ax.set_xlabel(x_dim)\n",
    "    ax.set_ylabel(y_dim)\n",
    "    ax.set_zlabel(z_dim)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll return to inlining plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means\n",
    "\n",
    "We start by loading the *KMeans* class and creating an instance specifying the number of desired clusters.  We use the *fit()* method to find clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clusters = KMeans(n_clusters=3)\n",
    "clusters.fit(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which clusters the algorithm assigned the data too using the *labels_* property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare cluster labels with the species labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(clusters.labels_):\n",
    "    print(label, iris_data.iloc[i].species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create scatter plots and and use the cluster labels to color the markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "row"
   },
   "outputs": [],
   "source": [
    "plot_data = input_data.copy()\n",
    "plot_data['cluster'] = clusters.labels_\n",
    "sns.pairplot(data=plot_data, hue='cluster', vars=input_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this with the known classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=iris_data, hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the location of each cluster's centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize these, we first create a DataFrame with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "centers = pd.DataFrame(clusters.cluster_centers_, columns=input_data.columns)\n",
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create pair-wise scatter plots showing the location of the computed clusters' centers and coloring based on species.  There are six ways of choosing two dimensions from four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dimensions = itertools.combinations(input_data.columns, 2)\n",
    "for column_names in two_dimensions:\n",
    "    x_dim, y_dim = column_names\n",
    "    \n",
    "    facet = sns.lmplot(x=x_dim, y=y_dim, hue=\"species\", data=iris_data, fit_reg=False)\n",
    "    \n",
    "    # plot centers\n",
    "    facet.ax.plot(centers[x_dim], centers[y_dim], 'ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN\n",
    "\n",
    "To use the DBSCAN algorithm, we start by importing the necessary class, creating an instance, and fitting the data.  Note that we do not specify the desired number of clusters for the DBSCAN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "clusters = DBSCAN()\n",
    "clusters.fit(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which clusters the algorithm assigned the data too using the *labels_* property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can display the cluster number and corresponding species for each row of data for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, value in enumerate(clusters.labels_):\n",
    "    print(value, iris_data.iloc[index].species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike K-means, DBSCAN does not compute clusters based on center points.  To get a visual sense of how the clusters compare to the original data, we can create pair-wise scatter plots using the DBSCAN results to for marker hues. We first add the results as a new column to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = input_data.copy()\n",
    "results[\"cluster\"] = clusters.labels_\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dimensions = itertools.combinations(input_data.columns, 2)\n",
    "for column_names in two_dimensions:\n",
    "    x_dim, y_dim = column_names    \n",
    "    sns.lmplot(x=x_dim, y=y_dim, hue=\"cluster\", data=results, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the algorithm identified three clusters, the clusters it identified don't correspond to the known species classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle Component Analysis\n",
    "\n",
    "In the iris data set, there are four dimensions of input/independent data that can be used to to analyze the data.  While we have been able to get meaningful results using all four dimensions, it would be simpler to work with fewer dimensions (and easier to visualize).  Principle Component Analysis (PCA) attempts to reduce the number of dimensions based on those that have the greatest variability.\n",
    "\n",
    "To calculate the PCA, we use the *PCA* class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "reduced_data = PCA(n_components=2).fit_transform(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using *fit_transform()* transforms the source data into values in the desired number of dimensions.  To plot the transformed data, we can create a DataFrame and copy the original species data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = pd.DataFrame(reduced_data, columns=['PC1', 'PC2'])\n",
    "plot_data = reduced_data.copy()\n",
    "plot_data['species'] = iris_data.species\n",
    "sns.lmplot(x='PC1', y='PC2', data=plot_data, hue='species', fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the notebook file and submit it on Blackboard for this week's lab.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- [Comparing different clustering algorithms on toy datasets](scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html)\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Use K-means to find three clusters of the reduced-dimensionality data created using the PCA algorithm, `reduced_data`.  Create a scatter plot with marker coloring based on the clusters found using K-means.  **Save the notebook and submit it for this week's exercise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
